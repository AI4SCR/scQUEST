<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Custom Models, Training &amp; Data Loaders &mdash; scQUEST  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Process FCS files and Create AnnData Object" href="process-fcs-files-and-create-annData-object.html" />
    <link rel="prev" title="scQUEST AML Tutorial" href="scQUEST_AML_tutorial.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> scQUEST
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="scQUEST_tutorial.html">scQUEST Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="scQUEST_AML_tutorial.html">scQUEST AML Tutorial</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Custom Models, Training &amp; Data Loaders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#custom-models">Custom Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pytorch-model">Pytorch Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pytorch-lightning-module">PyTorch Lightning Module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#custom-dataset">Custom Dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pytorch-dataset">Pytorch Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pytorch-lightning-datamodule">Pytorch Lightning Datamodule</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-the-datamodule">Using the datamodule</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#putting-everything-together">Putting everything together</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#training-settings">Training Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="#predict">Predict</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="process-fcs-files-and-create-annData-object.html">Process FCS files and Create AnnData Object</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_on_downsampling_and_clustering.html">scQUEST: Downsampling and Clustering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="scQUEST_api/scQUEST.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">scQUEST</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="tutorials.html">Tutorials</a> &raquo;</li>
      <li>Custom Models, Training &amp; Data Loaders</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Custom_models.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="custom-models-training-data-loaders">
<h1>Custom Models, Training &amp; Data Loaders<a class="headerlink" href="#custom-models-training-data-loaders" title="Permalink to this headline"></a></h1>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scQUEST</span> <span class="k">as</span> <span class="nn">scq</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">import</span> <span class="nn">torchmetrics</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="kn">import</span> <span class="nn">scanpy</span> <span class="k">as</span> <span class="nn">sc</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="s2">&quot;.* does not have many workers.*&quot;</span><span class="p">)</span>
</pre></div>
</div>
<section id="custom-models">
<h2>Custom Models<a class="headerlink" href="#custom-models" title="Permalink to this headline"></a></h2>
<p>The models used by the <code class="docutils literal notranslate"><span class="pre">Classifier</span></code> or the <code class="docutils literal notranslate"><span class="pre">Abnormality</span></code> class are defined in <a class="reference external" href="https://pytorch.org/">PyTorch</a> and <a class="reference external" href="https://www.pytorchlightning.ai/">PyTorch Lightning</a>. When using custom models we can either:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Define a model with PyTorch
2. Derive a PyTorch Lightning module from the PyTorch model
</pre></div>
</div>
<p>Using the pytorch lightning module enables the advanced user to further customize the training of the model itself.</p>
<section id="pytorch-model">
<h3>Pytorch Model<a class="headerlink" href="#pytorch-model" title="Permalink to this headline"></a></h3>
<p>To learn more about how to define PyTorch models refer to its exhaustive <a class="reference external" href="https://pytorch.org/tutorials/">documentation</a>.</p>
<p>In the <em>scQUEST Tutorial</em> we used by default 36 input features, but this can be easily tuned to fit different needs. In the following snippet we define a new model with more features than the default model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyTorchModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_in</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_in</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_in</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>use the autoencoder on some random data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyTorchModel</span><span class="p">()</span>
<span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([[0.5029, 0.5200, 0.5489, 0.4391, 0.4746],
        [0.5030, 0.5200, 0.5488, 0.4391, 0.4745],
        [0.5029, 0.5199, 0.5488, 0.4391, 0.4745],
        [0.5029, 0.5199, 0.5488, 0.4391, 0.4746],
        [0.5030, 0.5200, 0.5488, 0.4390, 0.4746],
        [0.5029, 0.5199, 0.5488, 0.4392, 0.4746],
        [0.5029, 0.5200, 0.5488, 0.4391, 0.4746],
        [0.5029, 0.5200, 0.5489, 0.4390, 0.4747],
        [0.5030, 0.5200, 0.5488, 0.4391, 0.4745],
        [0.5029, 0.5200, 0.5488, 0.4391, 0.4746]], grad_fn=&lt;SliceBackward0&gt;)
</pre></div>
</div>
<section id="apply-pytorch-model">
<h4>Apply Pytorch Model<a class="headerlink" href="#apply-pytorch-model" title="Permalink to this headline"></a></h4>
<p>That’s already it. We can now pass the model as an argument:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Abn</span> <span class="o">=</span> <span class="n">scq</span><span class="o">.</span><span class="n">Abnormality</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="pytorch-lightning-module">
<h3>PyTorch Lightning Module<a class="headerlink" href="#pytorch-lightning-module" title="Permalink to this headline"></a></h3>
<p>In the next step we derive a lightning module from our model. The lightning module defines all the steps to train our autoencoder. Advanced users can further customize the model training.
Note how we define a new <code class="docutils literal notranslate"><span class="pre">forward</span></code> function and how it differs from the <code class="docutils literal notranslate"><span class="pre">forward</span></code> function we defined in <code class="docutils literal notranslate"><span class="pre">MyTorchModel</span></code>. The <code class="docutils literal notranslate"><span class="pre">forward</span></code> function of <code class="docutils literal notranslate"><span class="pre">MyTorchModel</span></code> will return the reconstructed input data, on the other hand, in <code class="docutils literal notranslate"><span class="pre">MyLightningModule</span></code> we return the reconstruction error!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_in</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">MyTorchModel</span><span class="p">(</span><span class="n">n_in</span><span class="o">=</span><span class="n">n_in</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_mse</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># self(x) would call self.forward(x)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;fit_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_mse&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_mse</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># self(x) would call self.forward(x)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;val_mse&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_mse</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># self(x) would call self.forward(x)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_mse&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_mse</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>
</div>
<p>Let us instantiate the module and inspect it.</p>
<ul class="simple">
<li><p>we can see that our encoder and decoder were recognised as part of the model and we see the complete model structure</p></li>
<li><p>we can see the loss that will be used for training</p></li>
<li><p>and the metric logged during training and testing (<code class="docutils literal notranslate"><span class="pre">metric_mse</span></code>)</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">()</span>
<span class="n">module</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>MyLightningModule(
  (model): MyTorchModel(
    (encoder): Sequential(
      (0): Linear(in_features=100, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=16, bias=True)
      (3): ReLU()
      (4): Linear(in_features=16, out_features=8, bias=True)
      (5): ReLU()
      (6): Linear(in_features=8, out_features=4, bias=True)
    )
    (decoder): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=16, bias=True)
      (3): ReLU()
      (4): Linear(in_features=16, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=100, bias=True)
      (7): Sigmoid()
    )
  )
  (loss): MSELoss()
  (metric_mse): MeanSquaredError()
)
</pre></div>
</div>
<section id="apply-custom-module">
<h4>Apply Custom Module<a class="headerlink" href="#apply-custom-module" title="Permalink to this headline"></a></h4>
<p>And as before we pass the module as argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Abn</span> <span class="o">=</span> <span class="n">scq</span><span class="o">.</span><span class="n">Abnormality</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="custom-dataset">
<h2>Custom Dataset<a class="headerlink" href="#custom-dataset" title="Permalink to this headline"></a></h2>
<p>Customization of the training can also happen on the data level. By default, <code class="docutils literal notranslate"><span class="pre">Classifier</span></code> and <code class="docutils literal notranslate"><span class="pre">Abnormality</span></code> will pack the data in the <code class="docutils literal notranslate"><span class="pre">AnnData</span></code> object into a <code class="docutils literal notranslate"><span class="pre">pytorch.Dataset</span></code> and then derive a <code class="docutils literal notranslate"><span class="pre">pytorch_lightning.Datamodule</span></code> from it. Advanced users can provide such a <code class="docutils literal notranslate"><span class="pre">pytorch_lightning.Datamodule</span></code> which will be used instead of the default.</p>
<section id="pytorch-dataset">
<h3>Pytorch Dataset<a class="headerlink" href="#pytorch-dataset" title="Permalink to this headline"></a></h3>
<p>To continue the autoencoder example, we will now create our own datamodule for the training. In a first step we create a <code class="docutils literal notranslate"><span class="pre">pytorch.Dataset</span></code> class</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">item</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># iterate over dataset</span>
</pre></div>
</div>
</section>
<section id="pytorch-lightning-datamodule">
<h3>Pytorch Lightning Datamodule<a class="headerlink" href="#pytorch-lightning-datamodule" title="Permalink to this headline"></a></h3>
<p>In a next step we derive a Datamodule from this dataset. A datamodule simply packages everything needed to train the models in one class. More information can be found <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html">here</a>.</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">setup</span></code> function one can define how the dataset is split into the different <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">val</span></code> and <code class="docutils literal notranslate"><span class="pre">test</span></code> sets.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">test_size</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">validation_size</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">l</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">:</span> <span class="n">Dataset</span> <span class="o">=</span> <span class="n">dataset</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">l</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">=</span> <span class="n">l</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">*</span> <span class="n">validation_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span><span class="p">]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-the-datamodule">
<h3>Using the datamodule<a class="headerlink" href="#using-the-datamodule" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># convert to pytorch dataset to lightning datamodule</span>
<span class="n">dm</span> <span class="o">=</span> <span class="n">MyDataModule</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="n">Abn</span> <span class="o">=</span> <span class="n">scq</span><span class="o">.</span><span class="n">Abnormality</span><span class="p">(</span><span class="n">n_in</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">Abn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">,</span> <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

  | Name                    | Type             | Params
-------------------------------------------------------------
0 | model                   | DefaultAE        | 2.2 K 
1 | loss                    | MSELoss          | 0     
2 | metric_meansquarederror | MeanSquaredError | 0     
-------------------------------------------------------------
2.2 K     Trainable params
0         Non-trainable params
2.2 K     Total params
0.009     Total estimated model params size (MB)


────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        Test metric                 DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         test_loss              0.08185754716396332
test_metric_meansquarederror    0.08185756951570511
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
</section>
</section>
<section id="putting-everything-together">
<h2>Putting everything together<a class="headerlink" href="#putting-everything-together" title="Permalink to this headline"></a></h2>
<p>Let us now use a dataset from the <code class="docutils literal notranslate"><span class="pre">scanpy</span></code> package to put all the shown concepts together.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ad</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">pbmc68k_reduced</span><span class="p">()</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">var</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">ad</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
    <span class="p">[</span><span class="n">ad</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>  <span class="c1"># replicate examples to increase dataset size</span>
<span class="n">ad</span><span class="o">.</span><span class="n">obs_names_make_unique</span><span class="p">()</span>
<span class="n">ad</span><span class="o">.</span><span class="n">var</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ad</span><span class="o">.</span><span class="n">var</span><span class="p">,</span> <span class="n">var</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ad</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>/usr/local/Caskroom/miniconda/base/envs/scquest/lib/python3.8/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.
  utils.warn_names_duplicates(&quot;obs&quot;)





AnnData object with n_obs × n_vars = 7000 × 765
    obs: &#39;bulk_labels&#39;, &#39;n_genes&#39;, &#39;percent_mito&#39;, &#39;n_counts&#39;, &#39;S_score&#39;, &#39;G2M_score&#39;, &#39;phase&#39;, &#39;louvain&#39;
    var: &#39;n_counts&#39;, &#39;means&#39;, &#39;dispersions&#39;, &#39;dispersions_norm&#39;, &#39;highly_variable&#39;
    obsm: &#39;X_pca&#39;, &#39;X_umap&#39;
</pre></div>
</div>
<p>Since this is a simple toy examples we extract the highly variable genes and select the first <code class="docutils literal notranslate"><span class="pre">N</span></code> genes</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">ad</span> <span class="o">=</span> <span class="n">ad</span><span class="p">[:,</span> <span class="n">ad</span><span class="o">.</span><span class="n">var</span><span class="o">.</span><span class="n">highly_variable</span><span class="p">]</span>
<span class="n">ad</span> <span class="o">=</span> <span class="n">ad</span><span class="p">[:,</span> <span class="p">:</span><span class="n">N</span><span class="p">]</span>

<span class="n">ad</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">&quot;X_norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">ad</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
    <span class="n">ad</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">&quot;X_norm&quot;</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">ad</span><span class="o">.</span><span class="n">obs</span><span class="o">.</span><span class="n">louvain</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="p">:],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;magma&quot;</span>
<span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">ad</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">&quot;X_norm&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;magma&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="png" src="_images/Custom_models_26_0.png" /></p>
<section id="training-settings">
<h3>Training Settings<a class="headerlink" href="#training-settings" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># default</span>
<span class="n">Abn</span> <span class="o">=</span> <span class="n">scq</span><span class="o">.</span><span class="n">Abnormality</span><span class="p">(</span><span class="n">n_in</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">Abn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ad</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s2">&quot;X_norm&quot;</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

  | Name                    | Type             | Params
-------------------------------------------------------------
0 | model                   | DefaultAE        | 2.2 K 
1 | loss                    | MSELoss          | 0     
2 | metric_meansquarederror | MeanSquaredError | 0     
-------------------------------------------------------------
2.2 K     Trainable params
0         Non-trainable params
2.2 K     Total params
0.009     Total estimated model params size (MB)
/usr/local/Caskroom/miniconda/base/envs/scquest/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(


────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        Test metric                 DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         test_loss              0.014781960286200047
test_metric_meansquarederror    0.014781961217522621
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># custom model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyTorchModel</span><span class="p">(</span><span class="n">n_in</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">Abn</span> <span class="o">=</span> <span class="n">scq</span><span class="o">.</span><span class="n">Abnormality</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
<span class="n">Abn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ad</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s2">&quot;X_norm&quot;</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

  | Name                    | Type             | Params
-------------------------------------------------------------
0 | model                   | MyTorchModel     | 8.0 K 
1 | loss                    | MSELoss          | 0     
2 | metric_meansquarederror | MeanSquaredError | 0     
-------------------------------------------------------------
8.0 K     Trainable params
0         Non-trainable params
8.0 K     Total params
0.032     Total estimated model params size (MB)


────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        Test metric                 DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         test_loss               0.0106936264783144
test_metric_meansquarederror     0.0106936264783144
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># custom module</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="n">n_in</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">Abn</span> <span class="o">=</span> <span class="n">scq</span><span class="o">.</span><span class="n">Abnormality</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">module</span><span class="p">)</span>
<span class="n">Abn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ad</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s2">&quot;X_norm&quot;</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

  | Name       | Type             | Params
------------------------------------------------
0 | model      | MyTorchModel     | 8.0 K 
1 | loss       | MSELoss          | 0     
2 | metric_mse | MeanSquaredError | 0     
------------------------------------------------
8.0 K     Trainable params
0         Non-trainable params
8.0 K     Total params
0.032     Total estimated model params size (MB)


────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        test_loss           0.01118183322250843
        test_mse            0.01118183322250843
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># custom datamodule, default model</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">ad</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">&quot;X_norm&quot;</span><span class="p">])</span>
<span class="n">dm</span> <span class="o">=</span> <span class="n">MyDataModule</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>

<span class="n">Abn</span> <span class="o">=</span> <span class="n">scq</span><span class="o">.</span><span class="n">Abnormality</span><span class="p">(</span><span class="n">n_in</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">Abn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

  | Name                    | Type             | Params
-------------------------------------------------------------
0 | model                   | DefaultAE        | 2.2 K 
1 | loss                    | MSELoss          | 0     
2 | metric_meansquarederror | MeanSquaredError | 0     
-------------------------------------------------------------
2.2 K     Trainable params
0         Non-trainable params
2.2 K     Total params
0.009     Total estimated model params size (MB)
/usr/local/Caskroom/miniconda/base/envs/scquest/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(


────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        Test metric                 DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         test_loss              0.014520150609314442
test_metric_meansquarederror    0.014520152471959591
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># custom datamodule, custom model/module</span>
<span class="n">dm</span> <span class="o">=</span> <span class="n">MyDataModule</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="n">n_in</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>

<span class="n">Abn</span> <span class="o">=</span> <span class="n">scq</span><span class="o">.</span><span class="n">Abnormality</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">module</span><span class="p">)</span>
<span class="n">Abn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

  | Name       | Type             | Params
------------------------------------------------
0 | model      | MyTorchModel     | 8.0 K 
1 | loss       | MSELoss          | 0     
2 | metric_mse | MeanSquaredError | 0     
------------------------------------------------
8.0 K     Trainable params
0         Non-trainable params
8.0 K     Total params
0.032     Total estimated model params size (MB)


────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        test_loss           0.01485545001924038
        test_mse            0.01485545001924038
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
</section>
<section id="predict">
<h3>Predict<a class="headerlink" href="#predict" title="Permalink to this headline"></a></h3>
<p>Compute the reconstruction and visualise the error.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Abn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ad</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="s2">&quot;X_norm&quot;</span><span class="p">)</span>
<span class="n">ad</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>KeysView(Layers with keys: X_norm, abnormality)
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># estimate reconstruction error on the training data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">&quot;X_norm&quot;</span><span class="p">]</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">Abn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># access base torch model</span>
<span class="n">err</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">&quot;abnormality&quot;</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">dat</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
    <span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">,</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">err</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Input&quot;</span><span class="p">,</span> <span class="s2">&quot;Reconstruction&quot;</span><span class="p">,</span> <span class="s2">&quot;Error&quot;</span><span class="p">]</span>
<span class="p">):</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">Axes</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="s2">&quot;seismic&quot;</span> <span class="k">if</span> <span class="n">title</span> <span class="o">==</span> <span class="s2">&quot;Error&quot;</span> <span class="k">else</span> <span class="s2">&quot;magma&quot;</span>
    <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">title</span> <span class="o">==</span> <span class="s2">&quot;Error&quot;</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">dat</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;cells&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="png" src="_images/Custom_models_35_0.png" /></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="scQUEST_AML_tutorial.html" class="btn btn-neutral float-left" title="scQUEST AML Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="process-fcs-files-and-create-annData-object.html" class="btn btn-neutral float-right" title="Process FCS files and Create AnnData Object" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright IBM Corp. 2022.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>